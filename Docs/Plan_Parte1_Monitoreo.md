# Plan de trabajo â€” Parte 1: ObtenciÃ³n de registros desde tablas de Azure Storage

Fecha: 2025-09-04

Resumen
------
Este documento describe un plan de trabajo detallado para la primera parte del flujo: consultar y obtener registros desde tablas alojadas en Azure Storage segÃºn el JSON de request proporcionado. No se realiza implementaciÃ³n en este punto; el objetivo es acordar el comportamiento, contract, pasos, validaciones y consideraciones de seguridad.

JSON de request de ejemplo
-------------------------
{
  "applicationName": "AppSalud",
  "tablesToAnalyze": ["AppLog", "Log", "LogCsAuthenticate"],
  "startDateUtc": "2025-03-05T17:30:00Z",
  "endDateUtc": "2025-03-05T18:15:00Z",
  "maxRecords": 10
}

Checklist de requisitos (extraÃ­do del pedido)
---------------------------------------------
- [ ] Usar `applicationName` para identificar cadena de conexiÃ³n.
- [ ] Iterar las tablas listadas en `tablesToAnalyze`.
- [ ] Consultar registros por `Timestamp` entre `startDateUtc` y `endDateUtc`.
- [ ] Respetar `maxRecords` al retornar registros.
- [ ] Escribir un plan en Markdown dentro de `Docs/` (archivo creado aquÃ­).

Supuestos razonables (si falta precisiÃ³n)
-----------------------------------------
1. `maxRecords` se aplicarÃ¡ por tabla (lÃ­mite por tabla). Alternativa plausible: aplicar `maxRecords` como lÃ­mite global total; esto debe confirmarse en la siguiente fase.
  - AclaraciÃ³n: al obtener los registros, siempre se truncarÃ¡n los resultados devueltos a `maxRecords` por tabla. Por ejemplo, si la consulta encuentra 100 registros y `maxRecords` tiene el valor 10, la respuesta incluirÃ¡ Ãºnicamente 10 registros para esa tabla (los 10 primeros segÃºn orden de consulta/paginaciÃ³n).
2. Las tablas referidas son Azure Table Storage (modelo OData) o Azure Storage Tables compatibles.
3. `applicationName` tiene una correspondencia preexistente con una o varias cadenas de conexiÃ³n almacenadas de forma segura (Key Vault, variables de entorno o fichero configurado fuera del repositorio).

Contrato mÃ­nimo (Inputs / Outputs / Errores)
-------------------------------------------
- Inputs
  - JSON request (estructura arriba).
- Outputs (por tabla)
  - tableName: string
  - requestedRange: { startDateUtc, endDateUtc }
  - recordsReturned: integer
  - records: [ ... ] (hasta `maxRecords`)
  - status: OK | ERROR
  - errorMessage: string (si aplica)
- Errores esperados
  - Cadena de conexiÃ³n no encontrada para applicationName
  - Tabla inexistente o permisos insuficientes
  - Fechas invÃ¡lidas o rango vacÃ­o
  - LÃ­mite de tasa / timeouts de Azure

Flujo detallado (pasos operativos)
----------------------------------
1. ValidaciÃ³n inicial del request
   - Verificar presencia y formato de `applicationName`, `tablesToAnalyze`, `startDateUtc`, `endDateUtc`, `maxRecords`.
   - Parsear `startDateUtc` y `endDateUtc` como UTC. Rechazar si start > end.
2. ResoluciÃ³n de cadena de conexiÃ³n
   - Mapear `applicationName` a la cadena de conexiÃ³n (no almacenar en repo).
   - Verificar que la cadena de conexiÃ³n estÃ© accesible (KeyVault / env var).
3. ConexiÃ³n al servicio de tablas (per app/namespace segÃºn la cadena)
4. Para cada `tableName` en `tablesToAnalyze`:
   a. Validar que la tabla exista o manejar 404/no encontrada.
   b. Construir filtro OData para `Timestamp`:
      - Ejemplo: `Timestamp ge datetime'2025-03-05T17:30:00Z' and Timestamp le datetime'2025-03-05T18:15:00Z'`
   c. Ejecutar consulta con paginaciÃ³n si es necesario.
  d. Acumular hasta `maxRecords` (por tabla, segÃºn supuesto) y detener la consulta cuando se alcanza el lÃ­mite. Ejemplo: si la consulta coincide con 100 entidades y `maxRecords` = 10, devolveremos 10 entidades para esa tabla.
   e. Normalizar resultados (convertir Timestamp a ISO-8601 UTC, incluir PartitionKey/RowKey si relevantes).
5. Construir y retornar el objeto de respuesta por tabla con conteo `recordsReturned` = nÃºmero de items devueltos (no el total posible en la tabla si se truncÃ³).

Formato de respuesta sugerido (ejemplo)
--------------------------------------
{
  "applicationName": "AppSalud",
  "tableResults": [
    {
      "tableName": "AppLog",
      "requestedRange": {"startDateUtc":"...","endDateUtc":"..."},
      "recordsReturned": 10,
      "records": [ /* registros */ ],
      "status":"OK"
    },
    {
      "tableName": "NoExiste",
      "requestedRange": {...},
      "recordsReturned": 0,
      "records": [],
      "status":"ERROR",
      "errorMessage":"Table not found"
    }
  ]
}

Ejemplos de query / filtros (Azure Table Storage - OData)
---------------------------------------------------------
- OData filter sobre Timestamp:
  Timestamp ge datetime'2025-03-05T17:30:00Z' and Timestamp le datetime'2025-03-05T18:15:00Z'
- Si se necesita filtrar por PartitionKey, aÃ±adir `and PartitionKey eq '...'`.

PseudocÃ³digo (alto nivel)
-------------------------
- recibir request
- validar request
- connStr = resolverConnectionString(applicationName)
- client = crearClienteTablas(connStr)
- for tableName in tablesToAnalyze:
    - if not client.tableExists(tableName): registrar y devolver error para esa tabla
    - filter = buildTimestampFilter(startDateUtc, endDateUtc)
    - iterator = client.queryEntities(tableName, filter)
    - resultado = []
    - while iterator.hasNext() and resultado.length < maxRecords:
        - entidad = iterator.next()
        - resultado.push(normalizeEntity(entidad))
    - append resultado al response
- devolver response

Manejo de paginaciÃ³n y lÃ­mites
-----------------------------
- Usar la paginaciÃ³n nativa del SDK de Azure (continuation tokens).
- Parar tan pronto se alcanzan `maxRecords` (evitar iterar pÃ¡ginas innecesarias).
- Registrar mÃ©tricas: tiempo por tabla, nÃºmero de pÃ¡ginas leÃ­das, continuationTokens usados.

Casos de borde y validaciones adicionales
----------------------------------------
- Rango de fechas que no devuelve registros: retornar `recordsReturned: 0` con status OK.
- `maxRecords` <= 0 o invÃ¡lido: devolver error de validaciÃ³n.
- Fechas fuera de rango aceptable (por ejemplo > 1 aÃ±o atrÃ¡s): advertencia o rechazo segÃºn polÃ­tica.
- LÃ­mite global de memoria: si `tablesToAnalyze` es grande y `maxRecords` por tabla tambiÃ©n, calcular uso estimado y rechazar o stream.

Observaciones de seguridad
--------------------------
- Nunca commitear cadenas de conexiÃ³n en el repo.
- Usar Azure Key Vault o variables de entorno para almacenar connection strings.
- Registrar solo metadatos (tabla, conteo, tiempos), no los valores sensibles de los registros.
- Asegurar el transporte TLS y el uso de identidades gestionadas si es posible.

Pruebas y verificaciÃ³n
----------------------
- Prueba unitaria: funciÃ³n que genera el OData filter a partir de las fechas.
- IntegraciÃ³n (local): usar `AppLog.csv` como dataset de prueba para validar parsing y mapping de campos. (CSV usado solo para tests locales â€” verificar formato: Timestamp, Level, Message ...)
- Smoke test: ejecutar consulta sobre una tabla conocida y verificar que `recordsReturned` = min(totalMatch, maxRecords).
- Tests de error: cadena de conexiÃ³n faltante, tabla inexistente, fechas invÃ¡lidas.

MÃ©tricas y logs mÃ­nimos a capturar
----------------------------------
- requestId, applicationName, tableName
- tiempo de consulta por tabla
- registros devueltos por tabla
- errores y cÃ³digos de error

Plan de trabajo y estimaciÃ³n (entregables por hito)
---------------------------------------------------
1. RevisiÃ³n y aprobaciÃ³n del plan (este documento) â€” 0.5 dÃ­a
2. DiseÃ±o de la interfaz y contratos (schemas request/response + errores) â€” 0.5 dÃ­a
3. ImplementaciÃ³n de resoluciÃ³n de connection string y cliente de tablas â€” 1 dÃ­a
4. ImplementaciÃ³n de consulta por tabla con paginaciÃ³n y lÃ­mite `maxRecords` â€” 1.5 dÃ­as
5. Tests unitarios e integraciÃ³n con `AppLog.csv` â€” 1 dÃ­a
6. RevisiÃ³n de seguridad (Key Vault, logging) y ajustes â€” 0.5 dÃ­a
7. DocumentaciÃ³n final y handoff â€” 0.5 dÃ­a

Total estimado: 5.5 dÃ­as hÃ¡biles (ajustable segÃºn confirmaciÃ³n de supuestos)

Riesgos y mitigaciones
----------------------
- Secretos expuestos: Mitigar usando Key Vault y no almacenar secretos en cÃ³digo.
- VolÃºmenes grandes de datos: Mitigar usando streaming y lÃ­mites estrictos.
- Latencias/Rate limits de Azure: implementar reintentos exponenciales y circuit breaker.

Siguientes pasos propuestos
--------------------------
- Confirmar si `maxRecords` aplica por tabla o a nivel global.
- Confirmar dÃ³nde estÃ¡n almacenadas las cadenas de conexiÃ³n (Key Vault, env vars, archivo de configuraciÃ³n).
- Revisar `Monitoreo Proactivo.pdf` y `DiseÃ±o del Prompt para el monitoreo de Logs.pdf` para extraer requisitos funcionales adicionales (no extraer ni commitear secretos).
- Tras aprobaciÃ³n, pasar a la implementaciÃ³n (con prioridades y rama feature).

Requerimientos adicionales solicitados
-------------------------------------
Se solicita que la primera parte incluya los siguientes elementos de implementaciÃ³n y configuraciÃ³n:

1. Implementar un proyecto ASP.NET Core Web API con .NET 9 para la Parte 1 (ingest/consulta).
   - Estructura mÃ­nima: Controllers, Services, Models, Repositories.
   - Proveer endpoints para recibir el JSON request y devolver la respuesta por tabla.
2. DocumentaciÃ³n automÃ¡tica: integrar Swagger (OpenAPI) con UI activada en entornos de desarrollo.
   - Incluir metadatos: tÃ­tulo, versiÃ³n, contact, y ejemplo de request/response.
3. Cadenas de conexiÃ³n de almacenamiento (no commitear secretos)
   - Cuentas mencionadas por el solicitante:
     - AppSalud (placeholder): "${{AZURE_STORAGE_CONNECTIONSTRING_APPSALUD}}"
     - LinaChatbot (placeholder): "${{AZURE_STORAGE_CONNECTIONSTRING_LINACHATBOT}}"
   - RecomendaciÃ³n: **NO** pegar las claves en el repositorio. En su lugar:
     - Guardar los connection strings en Azure Key Vault o en las configuraciones seguras del pipeline (GitHub Actions Secrets / Azure DevOps Variable Groups).
     - En local, usar variables de entorno o un archivo `secrets.json` fuera del control de versiones.
   - Ejemplo de appsettings.json (solo placeholders):
     {
       "ConnectionStrings": {
         "AppSalud": "${{AZURE_STORAGE_CONNECTIONSTRING_APPSALUD}}",
         "LinaChatbot": "${{AZURE_STORAGE_CONNECTIONSTRING_LINACHATBOT}}"
       }
     }

Nota importante sobre las claves que enviaste
---------------------------------------------
Has incluido en tu mensaje cadenas que parecen ser connection strings completas (incluyendo AccountKey). Por seguridad y mejores prÃ¡cticas, NO voy a dejar esos valores en el repositorio ni en el plan. En su lugar el plan usa placeholders y recomienda almacenar y referenciar esos secretos desde Key Vault o variables de entorno en el pipeline.

Si deseas, puedo:
- AÃ±adir un apartado en el README con comandos para configurar los secretos en Azure Key Vault y cÃ³mo referenciarlos en el proyecto ASP.NET Core.
- Generar el proyecto base (plantilla) con Swagger y configuraciÃ³n para leer los connection strings desde `IConfiguration` usando placeholders.

Anexos
------
- Referencia de filtro OData: Timestamp ge datetime'START' and Timestamp le datetime'END'
- CSV de prueba sugerido: `Docs/AppLog.csv` (usar como dataset para tests locales)

---

Documento creado como plan para la Parte 1: obtenciÃ³n y retorno de registros desde tablas de Azure Storage.

AprobaciÃ³n
----------
Estado: Aprobado por el solicitante.
Fecha de aceptaciÃ³n: 2025-09-04
Notas: El plan queda listo para pasar a la fase de implementaciÃ³n segÃºn los hitos y supuestos aquÃ­ descritos. Si se requieren cambios (por ejemplo `maxRecords` global vs por tabla o inclusiÃ³n de secretos en Key Vault), documentarlos antes de iniciar la implementaciÃ³n.

Cambios realizados (resumen completo)
---------------------------------
### ImplementaciÃ³n inicial (2025-09-04)
- Se creÃ³ una plantilla de proyecto ASP.NET Core Web API en `src/MonitoreoStorage.Api` con endpoint POST `/api/logs/query`.
- Se integrÃ³ Swagger/OpenAPI para documentaciÃ³n automÃ¡tica en entorno de desarrollo.
- Se implementÃ³ el servicio `TableReadService` que consulta Azure Table Storage y aplica truncamiento a `maxRecords` por tabla.
- Se aÃ±adiÃ³ `appsettings.Development.json` con placeholders y el script `scripts/populate-appsettings.ps1` para poblarlo localmente (archivo ignorado por Git).
- Se aÃ±adiÃ³ `README.md` del proyecto con instrucciones de seguridad y ejemplo para Key Vault.

### DocumentaciÃ³n en espaÃ±ol (2025-09-05)
- Se aÃ±adiÃ³ documentaciÃ³n XML completa en espaÃ±ol a todos los controladores, servicios y modelos.
- Se tradujo toda la documentaciÃ³n interna del cÃ³digo al espaÃ±ol para mayor legibilidad.

### Filtrado especÃ­fico para AppSalud (2025-09-05)
- Se implementÃ³ lÃ³gica de filtrado especÃ­fica para la aplicaciÃ³n "AppSalud":
  - ExclusiÃ³n de campos `odata.etag` en todas las respuestas
  - Retorno de campos especÃ­ficos para AppSalud: `RowKey`, `Timestamp`, `TimeService`, `DocumentNumber`, `DocumentType`, `Type`, `NameMethod`, `Exception`
  - ExclusiÃ³n de tipos `REST_ExternalServiceTraceability` y `SOAP_ExternalServiceTraceability`

### Funcionalidad de filtrado por tiempo de respuesta (2025-09-06)
- Se aÃ±adiÃ³ la propiedad `MaxResponseTimeMs` al modelo `LogsQueryRequest` para filtrar registros por tiempo de respuesta.
- Se implementÃ³ lÃ³gica de filtrado post-consulta que:
  1. **Filtra por tipo:** Excluye registros con tipos especÃ­ficos (`REST_ExternalServiceTraceability`, `SOAP_ExternalServiceTraceability`)
  2. **Filtra por tiempo:** Incluye registros donde `TimeService > MaxResponseTimeMs` (para detectar respuestas lentas)
  3. **Concatena y deduplica:** Combina ambos conjuntos y elimina duplicados usando `RowKey` como identificador Ãºnico
- Se corrigiÃ³ la conversiÃ³n de `TimeService` de formato `TimeSpan` ("00:00:17.7765897") a milisegundos para comparaciÃ³n correcta.

### Estructura final del proyecto
```
src/MonitoreoStorage.Api/
â”œâ”€â”€ Controllers/LogsController.cs           # Endpoint principal con documentaciÃ³n XML
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ ITableReadService.cs               # Interfaz del servicio
â”‚   â””â”€â”€ TableReadService.cs                # ImplementaciÃ³n con filtrado complejo
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ LogsQueryRequest.cs                # Modelo de peticiÃ³n con MaxResponseTimeMs
â”‚   â”œâ”€â”€ LogsQueryResponse.cs               # Modelo de respuesta
â”‚   â””â”€â”€ TableQueryResult.cs                # Resultado por tabla
â”œâ”€â”€ appsettings.json                       # ConfiguraciÃ³n base
â”œâ”€â”€ appsettings.Development.json           # ConfiguraciÃ³n con placeholders (git ignored)
â””â”€â”€ Program.cs                             # ConfiguraciÃ³n de servicios y Swagger

scripts/
â””â”€â”€ populate-appsettings.ps1               # Script para configuraciÃ³n local segura

Docs/
â”œâ”€â”€ Plan_Parte1_Monitoreo.md              # Este documento
â”œâ”€â”€ README.md                              # Instrucciones del proyecto
â””â”€â”€ [archivos de anÃ¡lisis originales]
```

### Estado actual de funcionalidades
âœ… **Completado:**
- Consulta bÃ¡sica a Azure Table Storage con filtros de fecha
- Respeto al lÃ­mite `MaxRecords` por tabla
- Manejo de errores (tabla no encontrada, conexiÃ³n fallida)
- DocumentaciÃ³n Swagger/OpenAPI
- DocumentaciÃ³n XML en espaÃ±ol
- Filtrado especÃ­fico para AppSalud con campos personalizados
- Filtrado por tipos excluidos y tiempo de respuesta
- DeduplicaciÃ³n de registros basada en RowKey
- ConversiÃ³n correcta de TimeSpan a milisegundos

âœ… **Seguridad implementada:**
- Connection strings no hardcodeados
- Uso de placeholders para secretos
- Script de configuraciÃ³n local
- Archivo de configuraciÃ³n en .gitignore

ðŸ”„ **Pendiente para Parte 2:**
- AnÃ¡lisis de logs con LLM
- GeneraciÃ³n de alertas y reportes
- IntegraciÃ³n con sistemas de notificaciÃ³n
